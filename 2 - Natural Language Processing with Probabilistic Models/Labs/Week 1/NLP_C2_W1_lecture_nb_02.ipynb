{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Course 2 Week 1 Lesson : Building The Model - Lecture Exercise 02\n",
    "Estimated Time: 20 minutes\n",
    "<br>\n",
    "# Candidates from String Edits\n",
    "Create a list of candidate strings by applying an edit operation\n",
    "<br>\n",
    "### Imports and Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# data\r\n",
    "word = 'dearz' # ðŸ¦Œ"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splits\n",
    "Find all the ways you can split a word into 2 parts !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# splits with a loop\r\n",
    "splits_a = []\r\n",
    "for i in range(len(word)+1):\r\n",
    "    splits_a.append([word[:i],word[i:]])\r\n",
    "\r\n",
    "for i in splits_a:\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', 'dearz']\n",
      "['d', 'earz']\n",
      "['de', 'arz']\n",
      "['dea', 'rz']\n",
      "['dear', 'z']\n",
      "['dearz', '']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# same splits, done using a list comprehension\r\n",
    "splits_b = [(word[:i], word[i:]) for i in range(len(word) + 1)]\r\n",
    "\r\n",
    "for i in splits_b:\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('', 'dearz')\n",
      "('d', 'earz')\n",
      "('de', 'arz')\n",
      "('dea', 'rz')\n",
      "('dear', 'z')\n",
      "('dearz', '')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delete Edit\n",
    "Delete a letter from each string in the `splits` list.\n",
    "<br>\n",
    "What this does is effectivly delete each possible letter from the original word being edited. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# deletes with a loop\r\n",
    "splits = splits_a\r\n",
    "deletes = []\r\n",
    "\r\n",
    "print('word : ', word)\r\n",
    "for L,R in splits:\r\n",
    "    if R:\r\n",
    "        print(L + R[1:], ' <-- delete ', R[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "word :  dearz\n",
      "earz  <-- delete  d\n",
      "darz  <-- delete  e\n",
      "derz  <-- delete  a\n",
      "deaz  <-- delete  r\n",
      "dear  <-- delete  z\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's worth taking a closer look at how this is excecuting a 'delete'.\n",
    "<br>\n",
    "Taking the first item from the `splits` list :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# breaking it down\r\n",
    "print('word : ', word)\r\n",
    "one_split = splits[0]\r\n",
    "print('first item from the splits list : ', one_split)\r\n",
    "L = one_split[0]\r\n",
    "R = one_split[1]\r\n",
    "print('L : ', L)\r\n",
    "print('R : ', R)\r\n",
    "print('*** now implicit delete by excluding the leading letter ***')\r\n",
    "print('L + R[1:] : ',L + R[1:], ' <-- delete ', R[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "word :  dearz\n",
      "first item from the splits list :  ['', 'dearz']\n",
      "L :  \n",
      "R :  dearz\n",
      "*** now implicit delete by excluding the leading letter ***\n",
      "L + R[1:] :  earz  <-- delete  d\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the end result transforms **'dearz'** to **'earz'** by deleting the first character.\n",
    "<br>\n",
    "And you use a **loop** (code block above) or a **list comprehension** (code block below) to do\n",
    "<br>\n",
    "this for the entire `splits` list."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# deletes with a list comprehension\r\n",
    "splits = splits_a\r\n",
    "deletes = [L + R[1:] for L, R in splits if R]\r\n",
    "\r\n",
    "print(deletes)\r\n",
    "print('*** which is the same as ***')\r\n",
    "for i in deletes:\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "*** which is the same as ***\n",
      "earz\n",
      "darz\n",
      "derz\n",
      "deaz\n",
      "dear\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ungraded Exercise\n",
    "You now have a list of ***candidate strings*** created after performing a **delete** edit.\n",
    "<br>\n",
    "Next step will be to filter this list for ***candidate words*** found in a vocabulary.\n",
    "<br>\n",
    "Given the example vocab below, can you think of a way to create a list of candidate words ? \n",
    "<br>\n",
    "Remember, you already have a list of candidate strings, some of which are certainly not actual words you might find in your vocabulary !\n",
    "<br>\n",
    "<br>\n",
    "So from the above list **earz, darz, derz, deaz, dear**. \n",
    "<br>\n",
    "You're really only interested in **dear**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "vocab = ['dean','deer','dear','fries','and','coke']\r\n",
    "edits = list(deletes)\r\n",
    "\r\n",
    "print('vocab : ', vocab)\r\n",
    "print('edits : ', edits)\r\n",
    "\r\n",
    "candidates=[]\r\n",
    "\r\n",
    "### START CODE HERE ###\r\n",
    "#candidates = ??  # hint: 'set.intersection'\r\n",
    "candidates = set(vocab).intersection(set(edits))\r\n",
    "### END CODE HERE ###\r\n",
    "\r\n",
    "print('candidate words : ', candidates)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\n",
      "edits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "candidate words :  {'dear'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Expected Outcome:\n",
    "\n",
    "vocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\n",
    "<br>\n",
    "edits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\n",
    "<br>\n",
    "candidate words :  {'dear'}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "You've unpacked an integral part of the assignment by breaking down **splits** and **edits**, specifically looking at **deletes** here.\n",
    "<br>\n",
    "Implementation of the other edit types (insert, replace, switch) follow a similar methodology and should now feel somewhat familiar when you see them.\n",
    "<br>\n",
    "This bit of the code isn't as intuitive as other sections, so well done!\n",
    "<br>\n",
    "You should now feel confident facing some of the more technical parts of the assignment at the end of the week."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('deeplearning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "7bd95233e9c04de4911b7b9dc4f003d669080eb92d324c4c61e0dea7467d7a1b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}